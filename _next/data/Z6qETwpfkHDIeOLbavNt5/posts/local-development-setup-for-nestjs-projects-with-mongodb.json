{"pageProps":{"postData":{"id":"local-development-setup-for-nestjs-projects-with-mongodb","content":"\n## Introduction\n\nThis is a guide on how to setup a local development for [NestJS](https://docs.nestjs.com/) (a progressive [Node.js](https://nodejs.org/en/) framework) projects with [TypeScript](https://www.typescriptlang.org/), [MongoDB](https://www.mongodb.com/) and [mongo-express](https://github.com/mongo-express/mongo-express) using [Docker Compose](https://docs.docker.com/compose/). We'll be using [TypeORM](https://typeorm.io/) to connect and talk to our MongoDB database. This is your quick way to get started with Nest and it also involves extensions and libraries that helps us save time and energy when writing our code.\n\n## Skip\n\nIf you don't want to go through the steps below and you just want to get the boilerplate to save time, you can [clone it here](https://github.com/dominicarrojado/nestjs-mongodb-boilerplate) or run the [git](https://git-scm.com/) command below:\n\n```bash\ngit clone git@github.com:dominicarrojado/nestjs-mongodb-boilerplate.git my-app\n```\n\nDon't forget to ‚≠ê and share the [repo](https://github.com/dominicarrojado/nestjs-mongodb-boilerplate) if you like it!\n\n## Prerequisites\n\nUpon writing this post, I assume that you have some server-side application development background and basic knowledge regarding [npm](https://www.npmjs.com/), [yarn](https://classic.yarnpkg.com/lang/en/), [JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript), [TypeScript](https://www.typescriptlang.org/), [Docker](https://www.docker.com/), [Docker Compose](https://docs.docker.com/compose/), [Node.js](https://nodejs.org/en/), [NestJS](https://docs.nestjs.com/), [TypeORM](https://typeorm.io/) and [MongoDB](https://www.mongodb.com/).\n\nPlease make sure to install [Yarn](https://classic.yarnpkg.com/lang/en/) and [Docker Desktop](https://www.docker.com/products/docker-desktop/) in your system if you haven't. We use [Yarn](https://classic.yarnpkg.com/lang/en/) as our package manager, it's just like [npm](https://www.npmjs.com/) but _faster_. While we use [Docker](https://www.docker.com/) throughout the development lifecycle for fast, easy and portable application development.\n\nWe'll be using [Visual Studio Code](https://code.visualstudio.com/) as our [IDE](https://en.wikipedia.org/wiki/Integrated_development_environment) in setting this local development setup as we will utilize a few extensions from their [marketplace](https://marketplace.visualstudio.com/vscode).\n\nYou can also use [Postman](https://www.postman.com/) to interact with the API but that's optional as this won't be a full Nest tutorial.\n\n## Initialize your project\n\nSetting up a new project is quite simple with the [Nest CLI](https://docs.nestjs.com/cli/overview). With `yarn` installed, you can create a new Nest project with the following commands in your OS terminal:\n\n```bash\nyarn global add @nestjs/cli\nnest new my-app\n```\n\nChoose `yarn` as the package manager.\n\nOnce installed, let's run our project to see if everything is working fine by executing the command below:\n\n```bash\ncd my-app\nyarn start\n```\n\nOnce the application is running, open your browser and go to `http://localhost:3000/`. You should see a `Hello World!` message.\n\nTo watch for changes in your files, you can run the following command instead to start the application:\n\n```bash\nyarn start:dev\n```\n\nThis command will watch your files, when you have changes, it will automatically start recompiling and reloading the server. That's great for local development!\n\nTo build and run our Nest application for production, you can simply run the following command:\n\n```bash\nyarn build\nyarn start:prod\n```\n\n---\n\n## Install extensions in Visual Studio Code\n\nOpen the created project in your Visual Studio Code. Let's install [Prettier](https://prettier.io/), it's a code formatter that formats the code for us when we save file changes which is a time-saver.\n\nClick on the \"Extensions\" tab and look for \"Prettier\" and install it. You can also install it via this [link](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode).\n\nAfter Prettier is installed, we still need to enable the formatting feature by updating our settings in Visual Studio Code. Let's create a folder in the root directory and name it `.vscode`. Then, create a file inside it and name it `settings.json`. Then update the created file with the code below:\n\n```json\n{\n  \"editor.formatOnSave\": true,\n  \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n  \"editor.tabSize\": 2\n}\n```\n\nFeel free to modify `editor.tabSize` as that can be changed according to your preference.\n\nWhen we created a new Nest project, it already includes `.prettierrc` which is the config for Prettier to follow when formatting the code. These configs can be updated according to your preference.\n\nAlright, once the changes are done. That should make our Prettier work.\n\nYou can also install [ESLint](https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint) extension in Visual Studio Code to help with the linting checks.\n\n## Dockerfile\n\nA [Dockerfile](https://docs.docker.com/engine/reference/builder/) is text document that contains the instructions for Docker to assemble or build an image.\n\nLet's create a `Dockerfile` in the root folder of our application and add the following code below:\n\n```dockerfile\n# syntax=docker/dockerfile:1\n\nFROM node:16.14.2-alpine\nENV NODE_ENV=production\n\nWORKDIR /app\n\nCOPY [ \"package.json\", \"yarn.lock*\", \"./\" ]\n\nRUN yarn install --frozen-lockfile --production\n\nCOPY . .\n\nRUN yarn global add @nestjs/cli\nRUN yarn build\n\nCMD [ \"yarn\", \"start:prod\" ]\n```\n\nIf you're new to Docker or you need an explanation of what each line does, you can refer to the [section here](https://docs.docker.com/language/nodejs/build-images/#create-a-dockerfile-for-nodejs) from [Docker Documentation](https://docs.docker.com/), they explained it really well on while walking you through the process of creating a Dockerfile for Node.js. The `Dockerfile` we have created here is based from their example.\n\nNext, let's create a `.dockerignore` file in the root folder with the following content:\n\n```\nnode_modules\ndist\n```\n\nFiles or directories added in this file will get excluded in the build context. This will increase the build's performance and improve the context load time.\n\n---\n\n## Build image\n\nNow that we've created our `Dockerfile`, let's build our image. You are able to do this by the `docker build` command. The `docker build` command builds Docker images from a `Dockerfile` and a \"context\". A build's context is the set of files located in the specified PATH or URL. The Docker build process can access any of the files located in the context.\n\nThe build command optionally takes a `--tag` flag. The tag is used to set the name of the image and an optional tag in the format `name:tag`. We'll leave off the optional \"tag\" for now to help simplify things. If you do not pass a tag, Docker will use \"latest\" as its default tag. You'll see this in the last line of the build output.\n\nLet's build our first Docker image. Do remember to start your Docker Desktop application before executing the command below:\n\n```bash\ndocker build --tag nest-docker .\n```\n\n![Screenshot of docker build result](/images/posts/local-development-setup-for-nestjs-projects-with-mongodb/docker-build-result.png)\n\nIf you open your Docker Desktop, you'll see our `nest-docker` image in the \"Images\" tab.\n\n![Screenshot of Docker Desktop images](/images/posts/local-development-setup-for-nestjs-projects-with-mongodb/docker-desktop-images.png)\n\n## Run our image as a container\n\nNow that we have an image, we can run that image and see if our application is running correctly.\n\nA container is a normal operating system process except that this process is isolated and has its own file system, its own networking, and its own isolated process tree separate from the host.\n\nTo run an image inside of a container, we use the `docker run` command. Let's start our image and make sure it is running correctly. Execute the following command in your terminal.\n\n```bash\ndocker run --detach --publish 3000:3000 nest-docker\n```\n\nWe have 2 parameters in this command, that's `--detach` and `--publish 3000:3000`. So remember that contianers runs in isolation, hence we are not able to connect to it unless we publish it. To publish a port for our container, we used the `--publish` flag (-p for short) on the docker run command. The format of the `--publish` command is `[host port]:[container port]`. We can then access our application running in the `container port` via the `host port`. While `--detach` basically runs our container in detached mode or in the background so that our terminal (which where we ran the command) will not have it connected.\n\n![Screenshot of Docker Desktop containers](/images/posts/local-development-setup-for-nestjs-projects-with-mongodb/docker-desktop-containers.png)\n\nNow that the application is running, open your browser and go to `http://localhost:3000/`. You should see the same `Hello World!` message.\n\nNow we have successfully containerized our application.\n\n---\n\n## Multi-stage builds\n\nCurrently, we only containerized our application for **production**. But how about for (local) **development**? [Multi-stage builds](https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-builds) is the way to go. With multi-stage builds, we can use multiple `FROM` statements in our Dockerfile. Each `FROM` instruction can use a different base, and each of them begins a new stage of the build.\n\nLet's update our `Dockerfile` with the following code:\n\n```dockerfile\n# syntax=docker/dockerfile:1\n\nFROM node:16.14.2-alpine AS base\n\nWORKDIR /app\n\nCOPY [ \"package.json\", \"yarn.lock*\", \"./\" ]\n\nFROM base AS dev\nENV NODE_ENV=development\nRUN yarn install --frozen-lockfile\nCOPY . .\nCMD [ \"yarn\", \"start:dev\" ]\n\nFROM base AS prod\nENV NODE_ENV=production\nRUN yarn install --frozen-lockfile --production\nCOPY . .\nRUN yarn global add @nestjs/cli\nRUN yarn build\nCMD [ \"yarn\", \"start:prod\" ]\n```\n\nNow we can build the image with a target using the `docker build` command with a `--target` parameter. Let's use `dev` as our target to build and run our application for local development.\n\n```bash\ndocker build --target dev --tag nest-docker .\ndocker run --detach --publish 3000:3000 nest-docker\n```\n\nThis should run the application properly in `dev` mode.\n\n## Docker Compose\n\nJust using `Dockerfile` for our local development is not productive enough yet. When we make changes to our application, we will need to stop it, rebuild it and run it again. Also later on, we will need to configure the database to connect and use in our application. This whole process can be optimized using [Docker Compose](https://docs.docker.com/compose/). Docker Compose is a tool for defining and running multi-container Docker applications. With Docker Compose, you use a [YAML](https://en.wikipedia.org/wiki/YAML) file to configure your application's services. Then, with a single command, you create and start all the services from your configuration. That sounds great, right?\n\nLet's go ahead and create a `docker-compose.yml` file in the root folder and add the following code:\n\n```yml\nversion: '3.9'\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n      target: dev\n    ports:\n      - 3000:3000\n    volumes:\n      - ./src:/app/src\n```\n\nMost of the keys here should be familiar to you except the `volumes` key. The `volumes` key mounts the project directory (current directory, `./src`) on the host to `/app/src` directory inside the container, allowing you to modify the code on the fly, without having to rebuild the image.\n\nOnce the changes are saved, let's test it out by running the following command:\n\n```bash\ndocker-compose build\ndocker-compose up\n\n# OR\n\ndocker-compose up --build\n```\n\nDo remember to stop the docker image we ran previously via the Docker Desktop as we cannot run two applications on the same port.\n\nNow try making a change within the application code, go to `src/app.service.ts` and a few more `!` to the `Hello World` message. Once you save the changes, it will automatically send the new code to the container and that will trigger the rebuild of the application as it is running via `yarn start:dev` or `nest start --watch`. Awesome!\n\nLet's add this `docker-compose` command in our `package.json` scripts so that we can easily type and remember the command in a shorter form:\n\n```json\n{\n  \"name\": \"my-app\",\n  ...\n  \"scripts\": {\n    ...\n    \"docker-compose:dev\": \"docker-compose up --build\"\n  },\n  ...\n}\n```\n\n---\n\n## MongoDB and mongo-express\n\nIn this post, we'll use [MongoDB](https://www.mongodb.com/) as our database and [mongo-express](https://github.com/mongo-express/mongo-express) for our database admin tool to complete our local development setup.\n\nLet's update our `docker-compose.yml` to include their respective docker images:\n\n```yml\n...\n  app:\n    ...\n    depends_on:\n      - db\n\n  db:\n    image: mongo\n    restart: always\n    ports:\n      - 27017:27017\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: root\n      MONGO_INITDB_ROOT_PASSWORD: password\n\n  dbadmin:\n    image: mongo-express\n    restart: always\n    ports:\n      - 8081:8081\n    depends_on:\n      - db\n    environment:\n      ME_CONFIG_MONGODB_URL: mongodb://root:password@db:27017\n      ME_CONFIG_BASICAUTH_USERNAME: admin\n      ME_CONFIG_BASICAUTH_PASSWORD: mexpress\n\n```\n\nMongoDB image runs on port `27017` by default and we are just exposing the same port for our application and database admin portal to connect to. The only environment variables required are `MONGO_INITDB_ROOT_USERNAME` and `MONGO_INITDB_ROOT_PASSWORD`, the `MONGO_INITDB_DATABASE` is optional so we'll leave it be. You can read more about the MongoDB docker image [here](https://hub.docker.com/_/mongo).\n\nOn the other hand, mongo-express image runs on port `8081` by default and we are also just exposing the same port. There are three environment variables required: `ME_CONFIG_MONGODB_URL`, `ME_CONFIG_BASICAUTH_USERNAME` and `ME_CONFIG_BASICAUTH_PASSWORD`. You can read more about the other environment variables for mongo-express [here](https://hub.docker.com/_/mongo-express).\n\nWe can control the order of service startup and shutdown with the `depends_on` option. Hence we have added `db` as a dependency for our `app` and `dbadmin` service.\n\nLet's build and run our Docker Compose and everything should be working fine:\n\n```bash\nyarn docker-compose:dev\n```\n\nOnce all the environments are up and running, open your browser and go to `http://localhost:8081/`. You will be prompt to log in to mongo-express. Type in the username (`admin`) and password (`mexpress`) we have provided in the `docker-compose.yml`.\n\nAfter successfully logging in, you should see something like this:\n\n![Screenshot of databases in mongo-express](/images/posts/local-development-setup-for-nestjs-projects-with-mongodb/mongo-express-databases.png)\n\nThat means our MongoDB and mongo-express containers are set up successfully.\n\n---\n\n## TypeORM\n\nLet's continue and set up a database connection to our Nest application. We'll be using [TypeORM](https://typeorm.io/) which is an [ORM](https://en.wikipedia.org/wiki/Object-relational_mapping) that can help us develop any kind of application that uses databases in a JavaScript or TypeScript friendly way to communicate to the database rather than sending plain queries directly. It also handles a lot of things automatically such as database handling, data types, relations, etc. It also has database abstraction and they support a number of databases, that means we're not tied to a specific database, we can use MongoDB now and maybe use [PostgreSQL](https://www.postgresql.org/) tomorrow by just changing the configuration when initializing TypeORM and minor changes to the shape of your entities.\n\nTo use TypeORM in Nest. First, install the following dependencies:\n\n```bash\nyarn add @nestjs/typeorm typeorm mongodb\n```\n\nOnce the installation process is complete, we can import the `TypeOrmModule` into the root `AppModule` in `src/app.module.ts` and configure the database connection:\n\n```ts\n...\nimport { TypeOrmModule } from '@nestjs/typeorm';\n\n@Module({\n  imports: [\n    TypeOrmModule.forRoot({\n      type: 'mongodb',\n      url: 'mongodb://root:password@db/test?authSource=admin',\n      port: 27017,\n      autoLoadEntities: true,\n      synchronize: true,\n    }),\n  ],\n  ...\n})\nexport class AppModule {}\n```\n\nOnce you save the changes and run our application again, it should be all \"green\" in the terminal logs and that means the connection of the Nest application to our database is successful. Let's verify this by creating a `Users` module along with the controller and service using Nest CLI.\n\n```bash\nnest g module users\nnest g controller users --no-spec\nnest g service users --no-spec\n```\n\n---\n\nNext, we need to create an entity for `User`. In TypeORM, an entity is a class that maps to a database collection (or table when using PostgreSQL). Create a file `src/users/user.entity.ts` and add the following code:\n\n```ts\nimport { Column, Entity, ObjectID, ObjectIdColumn } from 'typeorm';\n\n@Entity()\nexport class User {\n  @ObjectIdColumn()\n  _id: ObjectID;\n\n  @Column()\n  firstName: string;\n\n  @Column()\n  lastName: string;\n\n  @Column({ default: true })\n  isActive: boolean;\n}\n```\n\nTypeORM supports the **repository design pattern**, so each entity has its own repository. These repositories can be obtained from the database connection.\n\nTo begin using the `User` entity, we need to let TypeORM know about it by inserting it into the array in the module `forFeature()` method argument and import it in the users module `src/users/users.module.ts`:\n\n```ts\n...\nimport { TypeOrmModule } from '@nestjs/typeorm';\nimport { User } from './user.entity';\n\n@Module({\n  imports: [TypeOrmModule.forFeature([User])],\n  ...\n})\nexport class UsersModule {}\n```\n\nThe user module uses the `forFeature()` method to define which repositories are registered in the current scope. With that in place, we can inject the `UsersRepository` into the `UsersService` using the `@InjectRepository()` decorator in `src/users/users.service.ts`:\n\n```ts\nimport { Injectable } from '@nestjs/common';\nimport { InjectRepository } from '@nestjs/typeorm';\nimport { Repository } from 'typeorm';\nimport { User } from './user.entity';\n\n@Injectable()\nexport class UsersService {\n  constructor(\n    @InjectRepository(User) private usersRepository: Repository<User>\n  ) {}\n\n  getAllUsers(): Promise<Array<User>> {\n    return this.usersRepository.find({});\n  }\n}\n```\n\nNow to expose a `GET` request handler in our application to get all the users, let's update our users controller `src/users/users.controller.ts`:\n\n```ts\nimport { Controller, Get } from '@nestjs/common';\nimport { User } from './user.entity';\nimport { UsersService } from './users.service';\n\n@Controller('users')\nexport class UsersController {\n  constructor(private usersService: UsersService) {}\n\n  @Get()\n  getAllUsers(): Promise<Array<User>> {\n    return this.usersService.getAllUsers();\n  }\n}\n```\n\nYou can open your Postman API client (or simply open your browser) and do a `GET` request to `http://localhost:3000/users`.\n\nIt should return a status of `200 OK` and return you an empty array `[]`.\n\nIf you still don't trust it, open the mongo-express tab in your browser. Create a database called `test`, then create a `user` collection and lastly add a new document as seen below:\n\n![Screenshot of creating a user document in mongo-express](/images/posts/local-development-setup-for-nestjs-projects-with-mongodb/mongo-express-create-user-document.png)\n\nAnd if you repeat the same `GET` request, it should now return you an array with the user object:\n\n```json\n[\n  {\n    \"_id\": \"629dc03db62e3877b07ce81a\",\n    \"firstName\": \"Dominic\",\n    \"lastName\": \"Arrojado\",\n    \"isActive\": true\n  }\n]\n```\n\n---\n\n## ConfigModule\n\nThere's another thing we need to do, so remember the values we used in initializing `TypeOrmModule`, passing configuration settings such as `host`, `port`, `username`, etc. Applications often run in different environments. Depending on the environment, different configuration settings should be used. Best practice is to store configuration variables in the environment.\n\nIn Node.js applications, it's common to use `.env` files, holding key-value pairs where each key represents a particular value, to represent each environment. Running an app in different environments is then just a matter of swapping in the correct `.env` file.\n\nA good approach for using this technique in Nest is to create a `ConfigModule` that exposes a `ConfigService` which loads the appropriate .env file. While you may choose to write such a module yourself, for convenience Nest provides the `@nestjs/config` package out-of-the box.\n\nTo begin using it, let's install the required dependencies:\n\n```bash\nyarn add @nestjs/config cross-env\n```\n\nThen head over to `src/app.module.ts` and import the `ConfigModule` here:\n\n```ts\n...\nimport { ConfigModule, ConfigService } from '@nestjs/config';\n\n@Module({\n  imports: [\n    ConfigModule.forRoot({\n      envFilePath: [`stage.${process.env.STAGE}.env`],\n    }),\n    TypeOrmModule.forRootAsync({\n      imports: [ConfigModule],\n      inject: [ConfigService],\n      useFactory: async (configService: ConfigService) => {\n        return {\n          type: 'mongodb',\n          url: configService.get('DB_URL'),\n          port: configService.get('DB_PORT'),\n          autoLoadEntities: true,\n          synchronize: true,\n        };\n      },\n    }),\n    UsersModule,\n  ],\n  ...\n})\nexport class AppModule {}\n```\n\nIn order to use the `ConfigModule` when initializing the `TypeOrmModule`, we'll need to switch from using `forRoot` to `forRootAsync` and take advantage of the dependency injection as written above.\n\nWe'll be using `STAGE` from the environment variables as the definition on which `.env` file will be loaded. Go ahead and create `stage.dev.env` and add the following config (you can create a file `stage.prod.env` later when you're ready to deploy your application to production):\n\n```\nPORT=3000\nDB_URL=mongodb://root:password@db/test?authSource=admin\nDB_PORT=27017\n```\n\nThen update `package.json` to include `STAGE` environment variable depending on the script:\n\n```json\n{\n  \"name\": \"my-app\",\n  ...\n  \"scripts\": {\n    ...\n    \"start:dev\": \"cross-env STAGE=dev nest start --watch\",\n    \"start:debug\": \"cross-env STAGE=dev nest start --debug --watch\",\n    \"start:prod\": \"cross-env STAGE=prod node dist/main\",\n    ...\n    \"test\": \"cross-env STAGE=dev jest\",\n    \"test:watch\": \"cross-env STAGE=dev jest --watch\",\n    \"test:cov\": \"cross-env STAGE=dev jest --coverage\",\n    ...\n  },\n  ...\n}\n```\n\nHere we are using [`cross-env`](https://github.com/kentcdodds/cross-env) which allows us to have a single command without worrying about setting or using the environment variable properly depending on the platform (e.g. [Windows](https://en.wikipedia.org/wiki/Microsoft_Windows), [MacOS](https://en.wikipedia.org/wiki/MacOS), [Linux](https://en.wikipedia.org/wiki/Linux)).\n\nLet's also update `main.ts` to use the `PORT` from the environment variables:\n\n```ts\nimport { Logger } from '@nestjs/common';\nimport { NestFactory } from '@nestjs/core';\nimport { AppModule } from './app.module';\n\nasync function bootstrap() {\n  const logger = new Logger();\n  const app = await NestFactory.create(AppModule);\n  const port = process.env.PORT;\n\n  await app.listen(port);\n\n  logger.log(`Application listening on port ${port}`);\n}\nbootstrap();\n```\n\nRun the Docker Compose environments again and everything should work fine as before.\n\n---\n\n## Config schema validation\n\nIt is standard practice to throw an exception during application startup if required environment variables haven't been provided or if they don't meet certain validation rules. The `@nestjs/config` package enables two different ways to do this as mentioned [here](https://docs.nestjs.com/techniques/configuration#schema-validation). [Joi](https://github.com/sideway/joi) is one of them which is what we're going to use.\n\nTo use Joi, we must install Joi package:\n\n```bash\nyarn add joi\n```\n\nNext, create the file `src/config.schema.ts` in the root folder with the following content:\n\n```ts\nimport * as Joi from 'joi';\n\nexport const configValidationSchema = Joi.object({\n  STAGE: Joi.string().required(),\n  PORT: Joi.number().default(3000).required(),\n  DB_URL: Joi.string().required(),\n  DB_PORT: Joi.number().default(27017).required(),\n});\n```\n\nThen let's make use of this by passing it in the `ConfigModule` option `validationSchema` in `src/app.module.ts`:\n\n```ts\n...\nimport { configValidationSchema } from './config.schema';\n\n@Module({\n  imports: [\n    ConfigModule.forRoot({\n      envFilePath: [`stage.${process.env.STAGE}.env`],\n      validationSchema: configValidationSchema,\n    }),\n    ...\n  ],\n  ...\n})\nexport class AppModule {}\n```\n\nThat's all you need to do. Try removing `DB_USERNAME` in `stage.dev.env` and run the Docker Compose environments. You'll get an error in the end stating: `Error: Config validation error: \"DB_USERNAME\" is required`. That's really helpful for knowing what went wrong while trying to run your application instead of getting a generic error `Unable to connect to the database` if we didn't do the config schema validation otherwise.\n\n---\n\n## Production and test environments\n\nTo finish off our local development setup, we want to be able to run tests using Docker Compose as well.\n\nFirst, let's update the `Dockerfile` to include the 3 scripts that runs the test:\n\n```dockerfile\n...\nCMD [ \"yarn\", \"start:dev\" ]\n\nFROM dev AS test\nENV NODE_ENV=test\nCMD [ \"yarn\", \"test\" ]\n\nFROM test AS test-cov\nCMD [ \"yarn\", \"test:cov\" ]\n\nFROM test AS test-watch\nENV GIT_WORK_TREE=/app GIT_DIR=/app/.git\nRUN apk add git\nCMD [ \"yarn\", \"test:watch\" ]\n\nFROM base AS prod\n...\n```\n\nNote that for `test:watch` to know what has change within the application code, it relies on [git](https://git-scm.com/), so we had some additional instructions for it.\n\nLet's create `production.yml` in the root folder with the following content:\n\n```yml\nservices:\n  app:\n    build:\n      target: prod\n```\n\nIt doesn't contain much as we only want to change the target because this will be appended to the original `docker-compose.yml`.\n\nThen create `test.yml` in the root folder with the following content:\n\n```yml\nservices:\n  app:\n    build:\n      target: test\n```\n\nThen create `test-cov.yml` in the root folder with the following content:\n\n```yml\nservices:\n  app:\n    build:\n      target: test-cov\n    volumes:\n      - ./coverage:/app/coverage\n```\n\nYou should already be familiar with `volumes`. Here, we we are basically syncing the `coverage` folder so that the coverage files generated from the application container will be synced with our current directory. Useful for [`CI/CD`](https://en.wikipedia.org/wiki/CI/CD) where you need to upload the test coverage to a service such as [`codecov`](https://about.codecov.io/).\n\nThen create `test-watch.yml` in the root folder with the following content:\n\n```yml\nservices:\n  app:\n    build:\n      target: test-watch\n    volumes:\n      - .git:/app/.git/\n```\n\nSame as above. Here, we are syncing the `.git` folder from our current directory with the `.git` folder of the application container. That is how it will know what files were changed in the application code and only run the test related to those changes.\n\n---\n\nLet's also move the `dbadmin` service block from `docker-compose.yml` to a new separate file called `dbadmin.yml` as it will only be utilized during `development` but we don't need to that service when we're just running tests.\n\n```yml\nservices:\n  dbadmin:\n    image: mongo-express\n    restart: always\n    ports:\n      - 8081:8081\n    depends_on:\n      - db\n    environment:\n      ME_CONFIG_MONGODB_URL: mongodb://root:password@db:27017\n      ME_CONFIG_BASICAUTH_USERNAME: admin\n      ME_CONFIG_BASICAUTH_PASSWORD: mexpress\n```\n\nThe updated `docker-compose.yml` should look like this now:\n\n```yml\nversion: '3.9'\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n      target: dev\n    ports:\n      - 3000:3000\n    volumes:\n      - ./src:/app/src\n    depends_on:\n      - db\n\n  db:\n    image: mongo\n    restart: always\n    ports:\n      - 27017:27017\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: root\n      MONGO_INITDB_ROOT_PASSWORD: password\n```\n\nLastly, update the `package.json` to add new scripts and utilize these new Docker Compose targets:\n\n```json\n{\n  \"name\": \"my-app\",\n  ...\n  \"scripts\": {\n    \"test\": \"cross-env STAGE=dev jest --runInBand\",\n    \"test:watch\": \"cross-env STAGE=dev jest --runInBand --watch\",\n    \"test:cov\": \"cross-env STAGE=dev jest --runInBand --coverage\",\n    ...\n    \"docker-compose:dev\": \"docker-compose -f docker-compose.yml -f dbadmin.yml up --build\",\n    \"docker-compose:test\": \"docker-compose -f docker-compose.yml -f test.yml up --build --exit-code-from app\",\n    \"docker-compose:test:cov\": \"docker-compose -f docker-compose.yml -f test-cov.yml up --build --exit-code-from app\",\n    \"docker-compose:test:watch\": \"docker-compose -f docker-compose.yml -f test-watch.yml up --build\",\n    \"docker-compose:prod\": \"docker-compose -f docker-compose.yml -f production.yml -f dbadmin.yml up --build\",\n    \"docker-compose:prod:build-only\": \"docker-compose -f docker-compose.yml -f production.yml build\"\n  },\n  ...\n}\n```\n\nIn the changes, we added `--runInBand` parameter to the scripts `test`, `test:watch` and `test:cov` found in `package.json`. This is done so we can run all tests serially for end-to-end testing that interacts with a database in docker compose, we don't want two or more test cases running in parallel where there's only 1 database as it might affect expected test results.\n\nAlso, with the `-f` option, we are able to use a second configuration file along with the original `docker-compose.yml`. For `docker-compose:test` and `docker-compose:test:cov`, we have a special option `--exit-code-from`, that's because we don't want the services in the Docker Compose to keep running even after completing all the tests, so we should ideally exit from `app`, which is the name of our Nest application container in the `docker-compose.yml`, and stop all the services.\n\n---\n\n## Final words\n\nWell, there you have it! You now have a full-fledged local development setup. Go ahead and start coding your Nest applications from this setup! I hope this was helpful for you, do share this post if you feel that it will be helpful for someone else too. I'll be doing another post soon on how to build an application using NestJS framework leveraging on this setup so stay tuned if you're intestered. ~\n\n## Online references\n\n- [Nest Documentation](https://docs.nestjs.com/)\n- [Docker Docs](https://docs.docker.com/)\n- [MongoDB in Dockerhub](https://hub.docker.com/_/mongo)\n- [mongo-express in Dockerhub](https://hub.docker.com/_/mongo-express)\n- [NestJS Zero to Hero Udemy Course](https://www.udemy.com/course/nestjs-zero-to-hero/)\n","previousPost":{"id":"building-a-link-shortener-api-with-nestjs-and-postgresql-with-tests-part-2","title":"Building a URL shortener API with NestJS and PostgreSQL with tests (Part 2)","date":"2022-05-18","excerpt":"Learn how to build server-side applications in an efficient, reliable and scalable way","category":"technology","videoUrl":"https://youtu.be/ysvUh_z7wjc"},"nextPost":{"id":"how-to-create-your-own-otp-input-in-react-and-typescript-with-tests-part-1","title":"How to create your own OTP input in React and TypeScript with tests (Part 1)","date":"2022-06-16","excerpt":"Learn how to build a modern OTP input component in a reactive and reusable way","category":"technology","videoUrl":"https://youtu.be/Qpo4gUfv2Fs"},"title":"Local development setup for NestJS projects with MongoDB","date":"2022-06-06","excerpt":"A quick way to get started with NestJS integrated with TypeScript, MongoDB and mongo-express using Docker Compose","category":"technology","videoUrl":""}},"__N_SSG":true}